---
title: "p8105_hw6_at3583"
author: "Alexandria D.Taylor,"
date: "`r format(Sys.Date())`"
output: github_document
---

**This homework explores linear modeling, logistic regression, bootstrap resampling, and cross-validated prediction using tidy R workflows.**

```{r markdown}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

library(tidyverse)
library(janitor)
library(broom)
library(purrr)
library(modelr)       
library(p8105.datasets) 

# Global colors + theme for plots
primary_color <- "steelblue3"
accent_color  <- "darkorange2"

theme_set(
  theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold"),
      legend.position = "bottom"
    )
)
```

# Problem 1. Homicides and Logistic Regression

```{r}
# Load and Clean Homicide data from Washington Post 
homicide_df <- read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
) |>
  clean_names()

# Clean + filter for analysis
homicide_city <- homicide_df |>
  mutate(
    city_state = str_c(city, ", ", state),
    # binary outcome: 1 = solved, 0 = not solved
    solved = case_when(
      disposition == "Closed by arrest" ~ 1,
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0,
      TRUE ~ NA_real_
    ),
    victim_age = as.numeric(victim_age)
  ) |>
  # drop cities with missing race or bad entry
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black")
  ) |>
  drop_na(solved, victim_age, victim_sex, victim_race)
```

Summary: The cleaned dataset contains **`r nrow(homicide_city)`** homicide records across  
**`r n_distinct(homicide_city$city_state)`** cities. After excluding Dallas, TX; Phoenix, AZ; Kansas City, MO; and Tulsa, AL, and restricting the analysis to victims who are White or Black, **`r nrow(homicide_city)`** cases remain. Victim age is stored as numeric; during cleaning, **`r sum(is.na(homicide_city$victim_age))`** records had non-numeric ages and were dropped from analysis.

## A. Baltimore, MD – logistic regression and adjusted OR

```{r}
baltimore_df <- homicide_city |>
  filter(city_state == "Baltimore, MD")

baltimore_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial()
)

baltimore_or <- baltimore_fit |>
  tidy(exponentiate = TRUE, conf.int = TRUE) |>
  filter(term == "victim_sexMale")

baltimore_or
```

Summary: In Baltimore, the adjusted odds ratio for solving a homicide when a victim is **male** (compared to female victims), controlling for age and race, is **`r round(baltimore_or$estimate, 2)`**, with a 95% confidence interval (CI) of (`r round(baltimore_or$conf.low, 2)`, `r round(baltimore_or$conf.high, 2)`).

## B. Logistic Regression Fitting
```{r}
# Nest by city_state and fit logistic regression in each city
city_models <- homicide_city |>
  group_by(city_state) |>
  nest(data = -city_state) |>
  mutate(
    fit = map(
      data,
      ~ glm(
          solved ~ victim_age + victim_sex + victim_race,
          data = .x,
          family = binomial()
        )
    ),
    results = map(
      fit,
      ~ tidy(.x, exponentiate = TRUE, conf.int = TRUE)
    )
  ) |>
  select(city_state, results) |>
  unnest(results) |>
  filter(term == "victim_sexMale") |>
  arrange(estimate)

city_models

# For Summary 
or_summary <- city_models |>
  summarise(
    min_or   = min(estimate),
    max_or   = max(estimate),
    n_gt1    = sum(conf.low > 1),
    n_lt1    = sum(conf.high < 1),
    n_cross1 = sum(conf.low <= 1 & conf.high >= 1)
  )
```

Summary: Across all cities, the adjusted odds ratios for solving homicides involving male victims range from **`r round(or_summary$min_or, 2)`** to **`r round(or_summary$max_or, 2)`**. In **`r or_summary$n_gt1`** cities, the 95% CI lies entirely above 1, indicating higher odds of case resolution for male victims; in **`r or_summary$n_lt1`** cities, the interval lies entirely below 1; and in **`r or_summary$n_cross1`** cities, the CI includes 1, suggesting no clear difference by victim sex.

## C. Plot ORs and CIs by City
```{r}
city_models |>
  ggplot(aes(
    x = reorder(city_state, estimate),
    y = estimate
  )) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "grey50") +
  geom_point(color = accent_color, size = 2.5) +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.2,
    color = primary_color
  ) +
  coord_flip() +
  labs(
    title = "Adjusted odds ratio of solving homicides: Male vs Female victims",
    x = "City",
    y = "Adjusted OR (male vs female victims)"
  )
```

Summary: Most cities have adjusted odds ratios close to 1, suggesting similar odds of solving homicides for male and female victims after controlling for age and race. A few cities show odds ratios clearly above 1, with CIs entirely above the null, indicating higher resolution rates for male victims. Other display wide intervals that cross 1, reflecting limited sample sizes and greater data uncertainty in sex-specific differences.

# Problem 2 -- Bootstrap for $R^2$ and $\hat{\beta}_1$, $\hat{\beta}_2$
  
```{r}
# Load and clean Central Park data

data("weather_df")
weather_lm_df <- weather_df |>
  drop_na(tmax, tmin, prcp)
```
 
## Bootstrap and Model Fitting

```{r}
set.seed(8105)

# 5000 bootstrap samples
boot_samples <- weather_lm_df |>
  modelr::bootstrap(n = 5000, id = "boot_id")

# Generate results
boot_results <- boot_samples |>
  mutate(
    model   = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glanced = map(model, glance),
    tidied  = map(model, tidy)
  ) |>
  transmute(
    boot_id,
    r_sq = map_dbl(glanced, "r.squared"),
    beta_prod = map_dbl(
      tidied,
      ~ .x |>
        filter(term %in% c("tmin", "prcp")) |>
        summarize(prod = prod(estimate)) |>
        pull(prod)
    )
  )

head(boot_results)
```

## 95% bootstrap CIs 
```{r}
# 95% CI for R^2
r2_ci <- boot_results |>
  summarise(
    lower = quantile(r_sq, 0.025),
    upper = quantile(r_sq, 0.975),
    median = median(r_sq)
  )

# 95% CI for beta1 * beta2
beta_ci <- boot_results |>
  summarise(
    lower = quantile(beta_prod, 0.025),
    upper = quantile(beta_prod, 0.975),
    median = median(beta_prod)
  )

r2_ci
beta_ci
```

Summary: The bootstrap distribution of R² has a median of **`r round(r2_ci$median, 3)`**, with a 95% interval from **`r round(r2_ci$lower, 3)`** to **`r round(r2_ci$upper, 3)`**. For the coefficient product \(\hat{\beta}_{tmin}\hat{\beta}_{prcp}\), the median is **`r signif(beta_ci$median, 3)`**, with a 95% interval of **(`r signif(beta_ci$lower, 3)`**, **`r signif(beta_ci$upper, 3)`)**.

## Distribution Plots
```{r}
# Distribution plot of R^2
boot_results |>
  ggplot(aes(x = r_sq)) +
  geom_histogram(
    bins = 40,
    fill = primary_color,
    color = "white",
    alpha = 0.8
  ) +
  labs(
    title = "Bootstrap distribution of R²",
    x = "R²",
    y = "Count"
  )

# Distribution plot of beta_tmin * beta_prcp
boot_results |>
  ggplot(aes(x = beta_prod)) +
  geom_histogram(
    bins = 40,
    fill = accent_color,
    color = "white",
    alpha = 0.8
  ) +
  labs(
    title = "Bootstrap distribution of β₁β₂ (tmin × prcp coefficients)",
    x = "β̂_tmin × β̂_prcp",
    y = "Count"
  )
```

Summary:Across the 5000 bootstrap samples, the R² values are tightly concentrated, with a median of `r round(r2_ci$median, 3)` and a 95% interval from `r round(r2_ci$lower, 3)` to `r round(r2_ci$upper, 3)`. This suggests that the linear model with *tmin* and *prcp* consistently explains a moderate proportion of the variability in *tmax* across resampled datasets.

The bootstrap distribution of the product \(\hat{\beta}_{tmin}\hat{\beta}_{prcp}\) is centered around `r signif(beta_ci$median, 3)`, with a 95% interval of (`r signif(beta_ci$lower, 3)`, `r signif(beta_ci$upper, 3)`). The spread and sign of this distribution reflect both the magnitudes and directions of the *tmin* and *prcp* coefficients, illustrating the uncertainty in their combined contribution to predicting *tmax*.